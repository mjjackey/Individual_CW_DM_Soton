{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#parser\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#NLP\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Jupyter Notebook\\COMP6237_Data_Mining\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Jupyter Notebook\\COMP6237_Data_Mining\\input2\\gap-html\n",
      "D:\\Code\\Jupyter Notebook\\COMP6237_Data_Mining\\input2\\gap-html\n"
     ]
    }
   ],
   "source": [
    "cwd=os.getcwd()\n",
    "fd_str=cwd+\"\\\\input2\\\\gap-html\"\n",
    "print(fd_str)\n",
    "fd_str1=os.path.join(cwd,\"input2\\\\gap-html\")\n",
    "print(fd_str1)\n",
    "fd=os.open(fd_str+\"\\\\gap_y-AvAAAAYAAJ\\\\00000001.html\",os.O_RDONLY)  #os.open() only can open the file not the dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gap_-C0BAAAAQAAJ', 'gap_2X5KAAAAYAAJ', 'gap_9ksIAAAAQAAJ', 'gap_aLcWAAAAQAAJ', 'gap_Bdw_AAAAYAAJ', 'gap_CnnUAAAAMAAJ', 'gap_CSEUAAAAYAAJ', 'gap_DhULAAAAYAAJ', 'gap_dIkBAAAAQAAJ', 'gap_DqQNAAAAYAAJ', 'gap_fnAMAAAAYAAJ', 'gap_GIt0HMhqjRgC', 'gap_IlUMAQAAMAAJ', 'gap_MEoWAAAAYAAJ', 'gap_m_6B1DkImIoC', 'gap_ogsNAAAAIAAJ', 'gap_pX5KAAAAYAAJ', 'gap_RqMNAAAAYAAJ', 'gap_TgpMAAAAYAAJ', 'gap_udEIAAAAQAAJ', 'gap_VPENAAAAQAAJ', 'gap_WORMAAAAYAAJ', 'gap_XmqHlMECi6kC', 'gap_y-AvAAAAYAAJ']\n"
     ]
    }
   ],
   "source": [
    "# 有效代码\n",
    "# Get all dirs\n",
    "dirnames = [name for name in os.listdir(fd_str)\n",
    "        if os.path.isdir(os.path.join(fd_str, name))]\n",
    "print(dirnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12142\n"
     ]
    }
   ],
   "source": [
    "allfiles_names=[]\n",
    "allfiles_names=[os.path.join(os.path.join(fd_str,dirname), name) for dirname in dirnames for name in os.listdir(os.path.join(fd_str,dirname)) \n",
    "            if name.endswith('.html') and os.path.isfile(os.path.join(os.path.join(fd_str,dirname), name))]  #一维列表\n",
    "print(len(allfiles_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 有效代码\n",
    "# Get all regular files\n",
    "allfiles_names=[]\n",
    "for dirname in dirnames:\n",
    "    dirpath=os.path.join(fd_str,dirname)\n",
    "    names = [os.path.join(dirpath, name) for name in os.listdir(dirpath) \n",
    "            if name.endswith('.html') and os.path.isfile(os.path.join(dirpath, name))]\n",
    "    allfiles_names.append(names)  #二维列表\n",
    "print(len(allfiles_names)) \n",
    "# print(allfiles_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有效代码\n",
    "def read_file(file_path):\n",
    "#     with open(file_path, 'rt',encoding='latin-1') as f:\n",
    "    with open(file_path, 'rt',encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有效代码\n",
    "def write_file(file_path,text):\n",
    "    with open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有效代码\n",
    "def extract_text_by_bs(doc_text):\n",
    "    \"\"\"提取html页面的所有文本信息。\n",
    "    参考：\n",
    "    http://stackoverflow.com/questions/328356/extracting-text-from-html-file-using-python\n",
    "    \"\"\"\n",
    "    title, text = '', ''\n",
    "    soup = BeautifulSoup(doc_text, 'lxml')\n",
    "    try:\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            # get text\n",
    "            title = soup.title.string\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            pass\n",
    "        text = soup.get_text()\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "    return title, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "1472\n"
     ]
    }
   ],
   "source": [
    "print(type(allfiles_names[0]))\n",
    "print(len(allfiles_names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data=read_file(allfiles_names[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<title>OCR Output</title>\n",
      "<meta http-equiv='content-type' content='text/html; charset=utf-8' />\n",
      "<meta http-equiv='content-style-type' content='text/css' />\n",
      "<meta name='ocr-capabilities' content='ocr_page ocr_par ocr_cinfo ocr_line' />\n",
      "<meta name='ocr-system' content='Coverups ' />\n",
      "<meta name='ocr-number-of-pages' content='1' />\n",
      "</head><body bgcolor='#ffffff'>\n",
      "<div class='ocr_page'>\n",
      "<div class='ocrx_block' title='bbox 50 1932 1561 2185'>\n",
      "<p class='ocr_par' title='bbox 50 1932 1561 2185' style='font-size:0pt;font-family:\"Times\";font-style:normal'></p>\n",
      "\n",
      "</div>\n",
      "<div class='ocrx_block' title='bbox 0 0 1 1'>\n",
      "<p class='ocr_par' title='bbox 0 0 1 1' style='font-size:0pt;font-family:\"Times\";font-style:normal'><span class='ocr_line' title='bbox 0 0 1 1'><span class='ocr_cinfo' title='bbox 0 0 1 1'> </span></span></p>\n",
      "\n",
      "</div>\n",
      "</div></body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, text=extract_text_by_bs(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Output OCR Output\n"
     ]
    }
   ],
   "source": [
    "print(title,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Jupyter Notebook\\COMP6237_Data_Mining\\input2\\gap-html\\gap_-C0BAAAAQAAJ\\00000013.html\n"
     ]
    }
   ],
   "source": [
    "print(allfiles_names[0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data=read_file(allfiles_names[0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Output OCR Output ERRATA In some copies of the Work the following errors will be found, which the reader is requested to correct. VOL. I. p.*. Col. Line 4 a 2Sb.« 17 b 17 b. « A 19 t. rj a 37 t. III A 33 b. IS h 31 b. 162 a 8 t. 169 b 14 b. 173 b SS t. 201 % 32 b. Ml b 2 C 33 and *• \" 34 t. 119 b S C. 242 A 24 t. S44 a 19 b. 251 h 6 t. ., • • 13 t. 255 a 6 and11 c. „ •> 8 L •• 12 t. ., 20 t. ■• •■ 31 t. ■.•,1 a 15 ant16 t- 342 b li b 34S a 24 b. 374 b 16 b. 375 b 7 b. 377 .i SIC for W., read E. for Tii. read xviii. for '\\fxetiet, read 'Axexiet. for Hierosolyma, read Jerusalem.) for Phylaes, read Pliylace. for Attica, read Athens. for Nakr, read Nahr. for Sons, read Sulib. for Moabitis, read Arbopolis. Vf.l■110 111 413 157464 50s 561 595 Line14 b. 10 b. 4 It.23 i). 4 t.16 b.33 t. 8 t.10 b. \\«t b 8 b. 152 m b 11. ,. t 3 t. 231 i. 37 t. -.7. a 1 ■• 1. ,, „ 10 b. Vt> h 21 and21' Mi a 111 t. r.i 351 b 24 b. 44'. b 9 I. VA h 24 b. s;» a 6 t. V, a 22 b. I 695 a 7 b. »* b 2 t. 599 a 16 b. 799 b 30 b. R81 a but. 884 a 940 b 32 t. 3S t. 1125 a 4 b. 1161 a 10 b. 1176 a 3 b. lnsa i. 2 t. 1)90 b 20 b. JI223 a 36 b. Il228 b 10 b. 4 J 16 t. 31 t. 3 b. for 392. read 302. for Thyrea, read Cynuria. for westerly, read easterly. for the latter river, read that rirer. for Mortuum Mars, read Palabstina. for Boeotia, read Phocis. for Thebes, read Thebe. for observations, read observation. for of Apsarus, read of the Apsaruss) for a magnificent, read an insignificant. for Khezius (Hezab), read Rhixius(Itnah). for the place, read Athenae. for between four and five, read aboutthree. for none of the houses were more thanone story high, read none of the nousappear to have been of any great height. for Babylonia, rend IUuran. for Auriatae, read.Autariatae. lor Marmartae, read Maenariae. for [Pan uses], read [Messknia]. for C. 5. Vincent, read C. Etpichcl. Forthe extreme SVV. headland of Lusi-tania, read a promontory of Lusitania,about 18 miles S. of the mouth of theTagus. for Limia, read Gallaecia. for rr^m,Ttfl'tmi, read r^txr^viau. for Thracians, read Thracian. 951 HH41024 9 b. to t. 16 b. 28 t33 t.13 t.5 t. b 3 t. 23 t.21 t.10 t. listline.26 t.34 t.12 t.11 and 16 t. for Elis, read Etis. for west, read east. for steepest, read deepest. for Helicon, read Cfthaeron. for Bura, read Achaia; Cynaetha. for Hierosolyma, read Jerusalem. for aud, read and. for Casso'tis, read Ca'ssotis. for 67, read 76. dele from and including \"when an im­portant,\" down to \"short period inBoeotia.\" for in the neighbourhood, read at Co-roneia. after the word battle, insert \"In con­sequence of this battle, the Athenianslost the supremacy which they had fora short time exercised in Boeotia.\" for Another and much more celebrated,read A celebrated. for Od. iv. 39, read Od. ix. 39, seqq. for 15, read 16. for Peneius, read Elis. for south, read north. for Nahr-le-Dan, read Nahr-cl-Dan. for Jordan ks, read Palaestina. alter &tctZ'f,rx«s, insert Thucy. i. 100, iv.102. for v. 5, read v. 52. before the reference [Europe], insertE.nneasdos [Amphipolib]. for Jughrami, read Jughirami. for Vulker-, read Vother-, for Limia, read Gallakcia. insert Aen. after straight, insert line. for this isthmus, read the isthmus. for Justjnopolis read Justinianopolis. for Parthenius, read Parthenias. VOL, II. for left, read right. The article Lebbn should come after article Lebbdos.for Botim-, reati Volt'm-.for Bolim-, read Volim-.for north-eastern, read north-westernfor Od. i. 40, read Od. ix. 196, scqq.for Od. ix. 197, read Od, ix. 209. for Nymphus, read Nyrophas. for Laconla, read Mussenia. The article Methydrium should precede art. Methymna in col. a.for p. 36, read p. 3, b.for rose, read descended,for Philip III., read Philip V.dele pp.for astoricracy, read aristocracy. for 367, read 359. for 362, read 352. for Gangites, read Angites. for Mars Ultor, read Temple op Mars Ultor.insert of.dele the note after the words ** near the Thermodon.\"for coeuis, read course.for Hec. 1. 105, read Herod, i. 103, seqq.for fog., read Voy. after &itu*j, insert Eth. Thcrmitanus.for J 4H0. read p. 4*0.for imperuosity, read impetuosity,for 59—88, read 57—88.)for Ukert ii. 2. S 230, read Ukert ii. pt. 2. p. 230.for $ 25, read p. 25. 't. means from the top; b. from the bottom, of the column.\n"
     ]
    }
   ],
   "source": [
    "title, text=extract_text_by_bs(file_data)\n",
    "print(title,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Jupyter Notebook\\COMP6237_Data_Mining\\input2\\gap-html\\gap_-C0BAAAAQAAJ\\00000013.html\n"
     ]
    }
   ],
   "source": [
    "'1,2,,3,'.split(',')\n",
    "file_name=allfiles_names[0][12]\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gap_-C0BAAAAQAAJ\n"
     ]
    }
   ],
   "source": [
    "path_list=file_name.split('\\\\')\n",
    "path=path_list[len(path_list)-2]\n",
    "print(path)  \n",
    "# fd_store=\"D:\\\\Code\\\\Jupyter Notebook\\\\COMP6237_Data_Mining\\\\out\"\n",
    "fd_store=os.path.join(cwd,\"output\")\n",
    "fd_store_path=os.path.join(fd_store, path)\n",
    "if(not os.path.exists(fd_store_path)):\n",
    "    os.mkdir(fd_store_path)\n",
    "name=path_list[len(path_list)-1]\n",
    "name2=name.split(\".\")[0]\n",
    "file_path=os.path.join(fd_store_path,name2+\".txt\")\n",
    "write_file(file_path,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472\n",
      "0,\n",
      "0,OCR Output\n",
      "0, OCR Output\n",
      "1, OCR Output\n",
      "1,OCR Output 800020427L ► ZOI5\n",
      "1, OCR Output OCR Output 800020427L ► ZOI5\n",
      "2, OCR Output OCR Output 800020427L ► ZOI5\n",
      "2,OCR Output DICTIONARY GREEK AND ROMAN GEOGRAPHY. ns\n",
      "2, OCR Output OCR Output 800020427L ► ZOI5 OCR Output DICTIONARY GREEK AND ROMAN GEOGRAPHY. ns\n",
      "3, OCR Output OCR Output 800020427L ► ZOI5 OCR Output DICTIONARY GREEK AND ROMAN GEOGRAPHY. ns\n",
      "3,OCR Output\n",
      "3, OCR Output OCR Output 800020427L ► ZOI5 OCR Output DICTIONARY GREEK AND ROMAN GEOGRAPHY. ns OCR Output\n"
     ]
    }
   ],
   "source": [
    "#合并一个文件目录下所有的html文档 \n",
    "text_combine=' '\n",
    "i=0\n",
    "print(len(allfiles_names[0]))\n",
    "for file_path in allfiles_names[0]:\n",
    "    file_data=read_file(file_path)\n",
    "    title, text=extract_text_by_bs(file_data)\n",
    "    if(i<4):\n",
    "        print(str(i)+\",\"+text_combine)\n",
    "#     text_combine = text_combine.join(text.strip())  不能按要求合并\n",
    "    text_combine = text_combine+\" \"+text.strip()\n",
    "    if(i<4):\n",
    "        print(str(i)+\",\"+text)\n",
    "        print(str(i)+\",\"+text_combine)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9198001\n"
     ]
    }
   ],
   "source": [
    "print(len(text_combine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output 800020427L ► ZOI5\n",
      "2, OCR Output OCR Output 800020427L ► ZOI5 OCR Output DICTIONARY GREEK AND ROMAN GEOGRAPHY. ns\n",
      "i:1\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output CReSlorecl througha arant in from (The Cartwright Foundation 5 ( PRINCETON UNIVERSITY K LIBRARY J\n",
      "2, OCR Output OCR Output CReSlorecl througha arant in from (The Cartwright Foundation 5 ( PRINCETON UNIVERSITY K LIBRARY J OCR Output\n",
      "i:2\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:3\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output 4 s3<? • (\n",
      "i:4\n",
      "0, OCR Output University of Virginia Library DG207 L5 B3 1797 V.1 ALD The history ot Rome.__ II ii II ill ii mi IJIIM imuii UX DD1 132 Sit,\n",
      "1, OCR Output University of Virginia Library DG207 L5 B3 1797 V.1 ALD The history ot Rome.__ II ii II ill ii mi IJIIM imuii UX DD1 132 Sit, OCR Output\n",
      "2, OCR Output University of Virginia Library DG207 L5 B3 1797 V.1 ALD The history ot Rome.__ II ii II ill ii mi IJIIM imuii UX DD1 132 Sit, OCR Output OCR Output\n",
      "i:5\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output Univcr? '- .-..3 General Library SystemUniversity of Wisconsin - Madison728 State StreetMadison, Wl 53706-1494U.S.A.\n",
      "2, OCR Output OCR Output Univcr? '- .-..3 General Library SystemUniversity of Wisconsin - Madison728 State StreetMadison, Wl 53706-1494U.S.A. OCR Output\n",
      "i:6\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output K'E ^\n",
      "2, OCR Output OCR Output K'E ^ OCR Output\n",
      "i:7\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:8\n",
      "0, OCR Output a&lral BMBBIB ::l - :-,.-.-----. - j. - ' - - :. . ,',-'.'.','.'.'\"---.\".'.'•- 'u-\"\". -: :- : --'•'.--'•-- -\n",
      "1, OCR Output a&lral BMBBIB ::l - :-,.-.-----. - j. - ' - - :. . ,',-'.'.','.'.'\"---.\".'.'•- 'u-\"\". -: :- : --'•'.--'•-- - OCR Output 600074686 / 121 f //\n",
      "2, OCR Output a&lral BMBBIB ::l - :-,.-.-----. - j. - ' - - :. . ,',-'.'.','.'.'\"---.\".'.'•- 'u-\"\". -: :- : --'•'.--'•-- - OCR Output 600074686 / 121 f // OCR Output\n",
      "i:9\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:10\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:11\n",
      "0, OCR Output -A , Pi %»\n",
      "1, OCR Output -A , Pi %» OCR Output 600010679T 16.3U •I: \\\n",
      "2, OCR Output -A , Pi %» OCR Output 600010679T 16.3U •I: \\ OCR Output .- /\"\n",
      "i:12\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:13\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output ^ ^\"^\"^\"^ *$\"^'^\"^* Harvard CollegeLibrary FROM THE BEQUEST OF JOHN HARVEY TREAT OF LAWRENCE, MASS.CLASS OF 1862\n",
      "2, OCR Output OCR Output ^ ^\"^\"^\"^ *$\"^'^\"^* Harvard CollegeLibrary FROM THE BEQUEST OF JOHN HARVEY TREAT OF LAWRENCE, MASS.CLASS OF 1862 OCR Output\n",
      "i:14\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output H/ COLLEGELIBRARY\n",
      "2, OCR Output OCR Output H/ COLLEGELIBRARY OCR Output\n",
      "i:15\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output ►\n",
      "2, OCR Output OCR Output ► OCR Output\n",
      "i:16\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output ifilrrarg uf tyxmteian Httiir^r»itgt.\n",
      "2, OCR Output OCR Output ifilrrarg uf tyxmteian Httiir^r»itgt. OCR Output\n",
      "i:17\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output |_-£/6,4./f ./a HARVARD COLLEGELIBRARY ,MrprNTNt Thayer.\n",
      "2, OCR Output OCR Output |_-£/6,4./f ./a HARVARD COLLEGELIBRARY ,MrprNTNt Thayer. OCR Output\n",
      "i:18\n",
      "0, OCR Output S^sa.\n",
      "1, OCR Output S^sa. OCR Output .*\n",
      "2, OCR Output S^sa. OCR Output .* OCR Output y E\n",
      "i:19\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output 1\n",
      "2, OCR Output OCR Output 1 OCR Output\n",
      "i:20\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:21\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:22\n",
      "0, OCR Output\n",
      "1, OCR Output OCR Output\n",
      "2, OCR Output OCR Output OCR Output\n",
      "i:23\n",
      "0, OCR Output iiiiiii : HX IHT3 B\n",
      "1, OCR Output iiiiiii : HX IHT3 B OCR Output ^arbart College Htbrarg. THE PARKMAN COLLECTION. BEQUEATHED BY Francis f* ar k m a n , (H.C. 1844). Received January /'. rflgt.\n",
      "2, OCR Output iiiiiii : HX IHT3 B OCR Output ^arbart College Htbrarg. THE PARKMAN COLLECTION. BEQUEATHED BY Francis f* ar k m a n , (H.C. 1844). Received January /'. rflgt. OCR Output Pa - ssa\n",
      "'NoneType' object has no attribute 'string'\n"
     ]
    }
   ],
   "source": [
    "# 有效代码\n",
    "fd_store=os.path.join(cwd,\"output\")\n",
    "for i in range(len(allfiles_names)):\n",
    "# for i in range(2):\n",
    "    print(\"i:\"+str(i))\n",
    "    text_combine=''\n",
    "    j=0\n",
    "    for file_path in allfiles_names[i]:\n",
    "        path_list=file_path.split('\\\\')\n",
    "        dir_name=path_list[len(path_list)-2]\n",
    "        fd_store_dir=os.path.join(fd_store, dir_name)\n",
    "        if(not os.path.exists(fd_store_dir)):\n",
    "            os.mkdir(fd_store_dir)\n",
    "        name=path_list[len(path_list)-1]\n",
    "        name2=name.split(\".\")[0]\n",
    "        file_store_path=os.path.join(fd_store_dir,name2+\".txt\")\n",
    "        \n",
    "        file_data=read_file(file_path) \n",
    "        title, text=extract_text_by_bs(file_data)\n",
    "        write_file(file_store_path,text)  #every file parsed from html files save to the folder\n",
    "        \n",
    "        text_combine = text_combine+\" \"+text.strip()\n",
    "        \n",
    "        if(j<3):\n",
    "            print(str(j)+\",\"+text_combine)\n",
    "        j=j+1\n",
    "        \n",
    "    file_com_path=os.path.join(fd_store,dir_name+\".txt\") #\n",
    "    write_file(file_com_path,text_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
